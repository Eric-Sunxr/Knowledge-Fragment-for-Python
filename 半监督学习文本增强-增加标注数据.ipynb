{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 半监督学习\n",
    "***半监督学习(Semi-Supervised Learning，SSL)*** 是模式识别和机器学习领域研究的重点问题，是监督学习与无监督学习相结合的一种学习方法。半监督学习使用大量的未标记数据，以及同时使用标记数据，来进行模式识别工作。当使用半监督学习时，将会要求尽量少的人员来从事工作，利用少量的已标注数据进行指导并预测未标记数据的标记，并合并到标记数据集中去；同时，又能够带来比较高的准确性，\n",
    "\n",
    "### 算法思路：\n",
    "- 生成模型：先计算样本特征的总体的联合分布，将所有有标注的样本计算出一个分布，然后把没有标注的样本放入这个分布中，看根据这个分布它该如何被标注，这个过程可能是迭代的\n",
    "- 物以类聚：将有标注和没有标注的样本进行相似的比较，相似度高的，就将无标注样本按照临近的有标注样本进行标注，类似迭代过程。\n",
    "\n",
    "#### 下面着重关注第二种，涉及的算法是标签传播算法\n",
    "### 标签传播算法\n",
    "标签传播算法（Label Propagation Algorithm）是基于图的半监督学习方法，基本思路是从已标记的节点的标签信息来预测未标记的节点的标签信息，利用样本间的关系，建立完全图模型。\n",
    "\n",
    "每个节点标签按相似度传播给相邻节点，在节点传播的每一步，每个节点根据相邻节点的标签来更新自己的标签，与该节点相似度越大，其相邻节点对其标注的影响权值越大，相似节点的标签越趋于一致，其标签就越容易传播。在标签传播过程中，保持已标记的数据的标签不变，使其将标签传给未标注的数据。最终当迭代结束时，相似节点的概率分布趋于相似，可以划分到一类中。\n",
    "\n",
    "标签传播表示半监督图推理算法的几个变种，且它有如下2个特性：\n",
    "- 可用于分类和回归任务\n",
    "- 将数据投射到另一维空间的内核方法(Kernel methods )\n",
    "\n",
    "值得注意的是，sklearn.semi_supervised中的半监督估计器能够利用这些额外的未标签数据来更好地捕捉到底层数据分布的形状(the shape of the underlying data distribution)，并对新的样本进行更好的泛化。当我们有极少量的有标签数据和大量的无标签数据时，半监督算法可以取得较好的表现。\n",
    "\n",
    "scikit-learn提供了两种标签传播模型 --- LabelPropagation和LabelSpreading，这两种模型的工作原理是在输入数据集的所有项上构建一个相似度图(similarity graph)。\n",
    "LabelPropagation和LabelSpreading有相同点，也存在明显的差异：\n",
    "- LabelPropagation和LabelSpreading对图的相似度矩阵( similarity matrix)的修改，以及对标签分布的箝位效应( the clamping effect )。箝位允许算法在一定程度上改变真的标签数据的权重。LabelPropagation算法对输入标签进行硬箝位(hard clamping)，也就是a = 0，LabelPropagation算法对输入标签进行硬箝位。这个箝位系数可以放宽，可以说是a = 0.2，这意味着我们将始终保留80%的原始标签分布，但算法得到的置信度在20%以内。\n",
    "\n",
    "- LabelPropagation使用从数据中构建的原始相似度矩阵（the raw similarity matrix），不做任何修改。相比之下，***LabelSpreading将具有正则化特性的损失函数最小化，因此它通常对噪声更稳健（划重点）。*** 该算法对原始图的修改版本进行迭代，并通过计算归一化的图Laplacian矩阵对边缘权重进行归一化。这个过程也被用于频谱聚类（Spectral clustering）中。\n",
    "\n",
    "- LabelSpreading类似于基本的标签传播算法（The basic Label Propagation algorithm），但使用了基于归一化的graph Laplacian和soft clamping 的亲和矩阵（affinity matrix）在标签间进行传播。\n",
    "\n",
    "标签传播模型有两种内置的内核方法。内核的选择对算法的可扩展性和性能都有影响。有以下2种方法可供选择。\n",
    "- rbf，距离离的越近越接近于1，距离离的越远越接近于0，由关键字gamma指定。\n",
    "- knn，找一个无标注的数据，然后取附近k个有标注的数据，无标注数据附近哪种标注的数据最多就取哪一个（以未标注的数据为圆心做knn，在指定范围内找到了有标注的数据，然后对未标注的数据进行打标，然后进行打标传播，直到未标注的数据全都标注以后，算法结束），由关键字n_neighbors指定。\n",
    "\n",
    "rbf内核将产生一个完全连接的图，在内存中用一个密集矩阵表示。这个矩阵可能非常大，再加上算法每次迭代都要进行一次完整的矩阵乘法计算，会导致运行时间过长。另一方面，KNN 内核将产生一个更有利于内存的稀疏矩阵，可以大大减少运行时间。\n",
    "由于LabelSpreading有较好的抗噪性，笔者将在下面的实例中使用该方法对含有少量标注数据和大量无标注的数据的样本集进行基于标签传播（Label Propagation）的无监督学习。\n",
    "为了方便，用于演示的数据来自sklearn自带的20newsgroups数据集，目前测试下来，这个半监督方法在长文本分类项目上效果奇好；如果是短文本的话，提取特征得用到当下最先进的transformer系预训练模型了。\n",
    "\n",
    "## 利用sklearn中的LabelSpreading进行小样本学习"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn import datasets\n",
    "from sklearn.semi_supervised import LabelSpreading\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 作为测试，只需要其中的5类即可，且训练集和测试集都用到，即参数“subset”取“all”。\n",
    "categories=[\n",
    "    'rec.autos',\n",
    "    'talk.politics.guns',\n",
    "    'talk.politics.mideast',\n",
    "    'rec.sport.baseball',\n",
    "    'comp.sys.mac.hardware',\n",
    "    'soc.religion.christian'\n",
    "]\n",
    "newsgroup_train=fetch_20newsgroups(subset='all',categories=categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将数据集打乱，随机化操作。\n",
    "# newsgroup_train['data'][0]\n",
    "rng=np.random.RandomState(0)\n",
    "indices=np.arange(len(newsgroup_train.target))\n",
    "rng.shuffle(indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 抽取文本数据的特征，用到的是tf-idf特征，并用到1gram和2gram，并去掉停用词，频率超高65%的特征词排除，且最大特征数为15000（词表中的最大词汇数）。\n",
    "vectorizer=TfidfVectorizer(\n",
    "    stop_words='english',\n",
    "    max_df=0.65,\n",
    "    ngram_range=(1,2),\n",
    "    max_features=15000\n",
    ")\n",
    "\n",
    "fea_train=vectorizer.fit_transform(newsgroup_train.data)\n",
    "y_train=newsgroup_train.target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "抽取文本数据的特征，用到的是tf-idf特征，并用到1gram和2gram，并去掉停用词，频率超高65%的特征词排除，且最大特征数为15000（词表中的最大词汇数）。\n",
    "\n",
    "当然，你可以通过改变max_iterations来标注更多的标签。标记更多的标签标签可以帮助我们了解这种主动学习技术的收敛速度。\n",
    "\n",
    "注意：当用拟合方法训练模型时，为未标记的点和标记的数据一起分配一个标识符是很重要的，本实例中使用的标识符是整型值-1。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_num=2000\n",
    "X=fea_train[indices[:test_num]]\n",
    "y=y_train[indices[:test_num]]\n",
    "images=np.array(newsgroup_train.data)[indices[:test_num]]\n",
    "\n",
    "n_total_samples=len(y)\n",
    "n_labeled_points=300\n",
    "max_iterations=20\n",
    "\n",
    "unlabeled_indices=np.arange(n_total_samples)[n_labeled_points:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 300,  301,  302, ..., 1997, 1998, 1999])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 检视下未标注数据的index，注意这是随机的。\n",
    "unlabeled_indices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在下面的每次迭代中，程序都会基于信息熵来显示其中机器***最拿不准的*** TOP10文本数据，这些数字可能包含错误，也可能不包含错误，这些数据其实是我们在语料标注中最需要标注的，它们对分类的影响极为重要，有时我们也可以在这些不确定的预标注数据中找到错误的标注。在这里，这些不确定样例将会使用它们的真实标签（True labels），投入到下一轮次的模型训练中。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "【迭代轮次】 0 ______________________________________________________________________\n",
      "LabelSpreading model: 300 个已标记 & 1700 个未标记 (2000 个总数)\n",
      "                        precision    recall  f1-score   support\n",
      "\n",
      "             rec.autos       0.72      0.74      0.73       282\n",
      "    talk.politics.guns       0.75      0.77      0.76       281\n",
      " talk.politics.mideast       0.78      0.73      0.75       281\n",
      "    rec.sport.baseball       0.87      0.85      0.86       319\n",
      " comp.sys.mac.hardware       0.84      0.81      0.82       268\n",
      "soc.religion.christian       0.83      0.91      0.87       269\n",
      "\n",
      "              accuracy                           0.80      1700\n",
      "             macro avg       0.80      0.80      0.80      1700\n",
      "          weighted avg       0.80      0.80      0.80      1700\n",
      "\n",
      "【混淆矩阵】\n",
      "[[209  18  20  13   5  17]\n",
      " [ 30 216  13  10   7   5]\n",
      " [ 17  29 204   8  13  10]\n",
      " [ 11  14   7 270   9   8]\n",
      " [ 14   9  12   8 216   9]\n",
      " [  8   2   7   0   8 244]]\n",
      "【最不确定样本呈现】\n",
      "\n",
      "…………………………………………………………………\n",
      "预测标签: comp.sys.mac.hardware\n",
      "真实标签: rec.autos\n",
      "******************************************************************************************\n",
      "…………………………………………………………………\n",
      "预测标签: talk.politics.mideast\n",
      "真实标签: comp.sys.mac.hardware\n",
      "******************************************************************************************\n",
      "…………………………………………………………………\n",
      "预测标签: comp.sys.mac.hardware\n",
      "真实标签: rec.sport.baseball\n",
      "******************************************************************************************\n",
      "…………………………………………………………………\n",
      "预测标签: rec.sport.baseball\n",
      "真实标签: comp.sys.mac.hardware\n",
      "******************************************************************************************\n",
      "…………………………………………………………………\n",
      "预测标签: soc.religion.christian\n",
      "真实标签: rec.autos\n",
      "******************************************************************************************\n",
      "…………………………………………………………………\n",
      "预测标签: talk.politics.guns\n",
      "真实标签: soc.religion.christian\n",
      "******************************************************************************************\n",
      "…………………………………………………………………\n",
      "预测标签: rec.autos\n",
      "真实标签: rec.sport.baseball\n",
      "******************************************************************************************\n",
      "…………………………………………………………………\n",
      "预测标签: rec.sport.baseball\n",
      "真实标签: rec.sport.baseball\n",
      "******************************************************************************************\n",
      "…………………………………………………………………\n",
      "预测标签: rec.sport.baseball\n",
      "真实标签: rec.sport.baseball\n",
      "******************************************************************************************\n",
      "…………………………………………………………………\n",
      "预测标签: rec.sport.baseball\n",
      "真实标签: rec.sport.baseball\n",
      "******************************************************************************************\n",
      "=========第 0 轮结束~============\n",
      "【迭代轮次】 1 ______________________________________________________________________\n",
      "LabelSpreading model: 310 个已标记 & 1690 个未标记 (2000 个总数)\n",
      "                        precision    recall  f1-score   support\n",
      "\n",
      "             rec.autos       0.74      0.76      0.75       280\n",
      "    talk.politics.guns       0.76      0.78      0.77       279\n",
      " talk.politics.mideast       0.77      0.76      0.76       276\n",
      "    rec.sport.baseball       0.88      0.84      0.86       318\n",
      " comp.sys.mac.hardware       0.85      0.80      0.82       268\n",
      "soc.religion.christian       0.85      0.90      0.87       269\n",
      "\n",
      "              accuracy                           0.81      1690\n",
      "             macro avg       0.81      0.81      0.81      1690\n",
      "          weighted avg       0.81      0.81      0.81      1690\n",
      "\n",
      "【混淆矩阵】\n",
      "[[212  19  16  13   5  15]\n",
      " [ 25 217  16   9   7   5]\n",
      " [ 15  26 209   7  11   8]\n",
      " [ 11  13  11 268   8   7]\n",
      " [ 14  10  13   8 214   9]\n",
      " [  8   2   8   0   8 243]]\n",
      "【最不确定样本呈现】\n",
      "\n",
      "…………………………………………………………………\n",
      "预测标签: comp.sys.mac.hardware\n",
      "真实标签: rec.sport.baseball\n",
      "******************************************************************************************\n",
      "…………………………………………………………………\n",
      "预测标签: rec.autos\n",
      "真实标签: rec.autos\n",
      "******************************************************************************************\n",
      "…………………………………………………………………\n",
      "预测标签: talk.politics.guns\n",
      "真实标签: talk.politics.mideast\n",
      "******************************************************************************************\n",
      "…………………………………………………………………\n",
      "预测标签: rec.sport.baseball\n",
      "真实标签: comp.sys.mac.hardware\n",
      "******************************************************************************************\n",
      "…………………………………………………………………\n",
      "预测标签: comp.sys.mac.hardware\n",
      "真实标签: comp.sys.mac.hardware\n",
      "******************************************************************************************\n",
      "…………………………………………………………………\n",
      "预测标签: rec.autos\n",
      "真实标签: comp.sys.mac.hardware\n",
      "******************************************************************************************\n",
      "…………………………………………………………………\n",
      "预测标签: comp.sys.mac.hardware\n",
      "真实标签: comp.sys.mac.hardware\n",
      "******************************************************************************************\n",
      "…………………………………………………………………\n",
      "预测标签: rec.autos\n",
      "真实标签: comp.sys.mac.hardware\n",
      "******************************************************************************************\n",
      "…………………………………………………………………\n",
      "预测标签: rec.sport.baseball\n",
      "真实标签: rec.autos\n",
      "******************************************************************************************\n",
      "…………………………………………………………………\n",
      "预测标签: comp.sys.mac.hardware\n",
      "真实标签: rec.sport.baseball\n",
      "******************************************************************************************\n",
      "=========第 1 轮结束~============\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-18-fb9f21583e4f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     14\u001b[0m                         \u001b[0mn_jobs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m                         )\n\u001b[1;32m---> 16\u001b[1;33m     \u001b[0mlp_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m     \u001b[0mpredicted_labels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlp_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransduction_\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0munlabeled_indices\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\Anaconda\\lib\\site-packages\\sklearn\\semi_supervised\\_label_propagation.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    231\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    232\u001b[0m         \u001b[1;31m# actual graph construction (implementations should override this)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 233\u001b[1;33m         \u001b[0mgraph_matrix\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_build_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    234\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    235\u001b[0m         \u001b[1;31m# label construction\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\Anaconda\\lib\\site-packages\\sklearn\\semi_supervised\\_label_propagation.py\u001b[0m in \u001b[0;36m_build_graph\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    510\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnn_fit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    511\u001b[0m         \u001b[0mn_samples\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mX_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 512\u001b[1;33m         \u001b[0maffinity_matrix\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_kernel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mX_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    513\u001b[0m         \u001b[0mlaplacian\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcsgraph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlaplacian\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maffinity_matrix\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnormed\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    514\u001b[0m         \u001b[0mlaplacian\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m-\u001b[0m\u001b[0mlaplacian\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\Anaconda\\lib\\site-packages\\sklearn\\semi_supervised\\_label_propagation.py\u001b[0m in \u001b[0;36m_get_kernel\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    137\u001b[0m                 return self.nn_fit.kneighbors_graph(self.nn_fit._fit_X,\n\u001b[0;32m    138\u001b[0m                                                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_neighbors\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 139\u001b[1;33m                                                     mode='connectivity')\n\u001b[0m\u001b[0;32m    140\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    141\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnn_fit\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkneighbors\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreturn_distance\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\Anaconda\\lib\\site-packages\\sklearn\\neighbors\\_base.py\u001b[0m in \u001b[0;36mkneighbors_graph\u001b[1;34m(self, X, n_neighbors, mode)\u001b[0m\n\u001b[0;32m    757\u001b[0m         \u001b[1;31m# construct CSR matrix representation of the k-NN graph\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    758\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mmode\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'connectivity'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 759\u001b[1;33m             \u001b[0mA_ind\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkneighbors\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_neighbors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreturn_distance\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    760\u001b[0m             \u001b[0mn_queries\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mA_ind\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    761\u001b[0m             \u001b[0mA_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mones\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_queries\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mn_neighbors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\Anaconda\\lib\\site-packages\\sklearn\\neighbors\\_base.py\u001b[0m in \u001b[0;36mkneighbors\u001b[1;34m(self, X, n_neighbors, return_distance)\u001b[0m\n\u001b[0;32m    663\u001b[0m                 delayed_query(\n\u001b[0;32m    664\u001b[0m                     self._tree, X[s], n_neighbors, return_distance)\n\u001b[1;32m--> 665\u001b[1;33m                 \u001b[1;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mgen_even_slices\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    666\u001b[0m             )\n\u001b[0;32m    667\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\Anaconda\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1040\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1041\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1042\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1043\u001b[0m             \u001b[1;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1044\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\Anaconda\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    919\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    920\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'supports_timeout'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 921\u001b[1;33m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    922\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    923\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\Anaconda\\lib\\multiprocessing\\pool.py\u001b[0m in \u001b[0;36mget\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    649\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    650\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 651\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    652\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mready\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    653\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\Anaconda\\lib\\multiprocessing\\pool.py\u001b[0m in \u001b[0;36mwait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    646\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    647\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 648\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_event\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    649\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    650\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\Anaconda\\lib\\threading.py\u001b[0m in \u001b[0;36mwait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    550\u001b[0m             \u001b[0msignaled\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_flag\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    551\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 552\u001b[1;33m                 \u001b[0msignaled\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    553\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    554\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\Anaconda\\lib\\threading.py\u001b[0m in \u001b[0;36mwait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    294\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m    \u001b[1;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    295\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 296\u001b[1;33m                 \u001b[0mwaiter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    297\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    298\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "for i in range(max_iterations):\n",
    "    if len(unlabeled_indices) == 0:\n",
    "        print(\"没有待打标的候选标签项\")\n",
    "        break\n",
    "    y_train = np.copy(y)\n",
    "    y_train[unlabeled_indices] = -1\n",
    "\n",
    "    lp_model = LabelSpreading(\n",
    "                        gamma=0.25, \n",
    "                        kernel='knn',\n",
    "                        alpha = 0.5,\n",
    "                        n_neighbors =15,\n",
    "                        max_iter=50,\n",
    "                        n_jobs = -1\n",
    "                        )\n",
    "    lp_model.fit(X.toarray(), y_train)\n",
    "\n",
    "    predicted_labels = lp_model.transduction_[unlabeled_indices]\n",
    "    true_labels = y[unlabeled_indices]\n",
    "\n",
    "    cm = confusion_matrix(true_labels, predicted_labels,\n",
    "                          labels=lp_model.classes_)\n",
    "\n",
    "    print(\"【迭代轮次】 %i %s\" % (i, 70 * \"_\"))\n",
    "    print(\"LabelSpreading model: %d 个已标记 & %d 个未标记 (%d 个总数)\"\n",
    "          % (n_labeled_points, n_total_samples - n_labeled_points,\n",
    "             n_total_samples))\n",
    "\n",
    "    print(classification_report(\n",
    "        true_labels, \n",
    "            predicted_labels,\n",
    "            target_names = [\n",
    "                     'rec.autos',\n",
    "                     'talk.politics.guns',\n",
    "                     'talk.politics.mideast',\n",
    "                     'rec.sport.baseball',\n",
    "                     'comp.sys.mac.hardware',\n",
    "                     'soc.religion.christian']\n",
    "            ))\n",
    "\n",
    "    print(\"【混淆矩阵】\")\n",
    "    print(cm)\n",
    "\n",
    "    # compute the entropies of transduced label distributions\n",
    "    pred_entropies = stats.distributions.entropy(\n",
    "        lp_model.label_distributions_.T)\n",
    "\n",
    "    # select up to 10 digit examples that the classifier is most uncertain about\n",
    "    uncertainty_index = np.argsort(pred_entropies)[::-1]\n",
    "    uncertainty_index = uncertainty_index[\n",
    "        np.in1d(uncertainty_index, unlabeled_indices)][:10]\n",
    "\n",
    "    # keep track of indices that we get labels for\n",
    "    delete_indices = np.array([], dtype=int)\n",
    "\n",
    "\n",
    "    print('【最不确定样本呈现】\\n',images)\n",
    "    for index, image_index in enumerate(uncertainty_index):\n",
    "        image = images[image_index]\n",
    "\n",
    "\n",
    "        if i < max_iterations:\n",
    "\n",
    "            print('……………'*5)\n",
    "            print(\"预测标签: {}\\n真实标签: {}\".format(\n",
    "                newsgroup_train.target_names[lp_model.transduction_[image_index]], newsgroup_train.target_names[y[image_index]]))\n",
    "            print('******************'*5)\n",
    "\n",
    "        # labeling 10 points, remote from labeled set\n",
    "        delete_index, = np.where(unlabeled_indices == image_index)\n",
    "        delete_indices = np.concatenate((delete_indices, delete_index))\n",
    "\n",
    "    unlabeled_indices = np.delete(unlabeled_indices, delete_indices)\n",
    "    n_labeled_points += len(uncertainty_index)\n",
    "    print('=========第 {} 轮结束~============'.format(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
